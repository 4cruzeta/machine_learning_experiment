{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/marcelocruzeta/machine-learning-experiment?scriptVersionId=248543600\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"b5ef15bf","metadata":{"papermill":{"duration":0.004101,"end_time":"2025-07-02T18:33:52.546895","exception":false,"start_time":"2025-07-02T18:33:52.542794","status":"completed"},"tags":[]},"source":["# 1. Personality Classification Project\n","\n","## Project Overview\n","\n","This project aims to classify individuals as either Introverts or Extroverts based on various behavioral and social characteristics using machine learning techniques. The primary objective is to build and validate models that can effectively predict personality types from input features derived from a dataset.\n","\n","## Dataset\n","\n","The dataset used in this project comprises responses to questions related to social behavior, emotional experiences, and personal preferences. Key features include:\n","\n","- **Stage_fear**: Indicating fear of public speaking.\n","- **Drained_after_socializing**: Reflecting how individuals feel after interacting socially.\n","- **Time_spent_Alone**: The amount of time spent alone.\n","- **Social_event_attendance**: Frequency of attendance at social events.\n","- **Going_outside**: How often individuals engage in outdoor activities.\n","- **Friends_circle_size**: The size of their social circle.\n","- **Post_frequency**: How often they post on social media.\n","\n","## Methodology\n","\n","### Data Preprocessing\n","- **Handling Missing Values**: Categorical variables were filled with 'Unknown' and mapped to numeric values. Numeric features were imputed using the `IterativeImputer` technique to fill in any missing gaps.\n","- **Model**: Data was split into training and sets to train and evaluate model performance effectively.\n","\n","### Model Training\n","Three distinct machine learning models were utilized to predict personality types:\n","1. **Random Forest Classifier**: A robust ensemble learning method used for classification tasks.\n","2. **CatBoost Classifier**: A gradient boosting library that efficiently handles categorical features without extensive pre-processing.\n","3. **XGBoost Classifier**: An optimized gradient boosting framework designed for speed and performance.\n","\n","The models underwent training on the training dataset, followed by evaluation on the validation set to assess their accuracy and classification metrics. \n","\n","### Majority Voting for Consensus\n","To enhance prediction reliability, predictions from the three models were combined using a majority voting approach. For each prediction:\n","- If at least two out of three models agree on a personality type, that type is selected as the final prediction.\n","- This method helps mitigate individual model biases and improves overall prediction robustness.\n","\n","## Final Submission\n","The final predictions were compiled into a submission file named `submission.csv`, containing two columns: `id` and `Predicted_Personality`, ready for evaluation and further analysis.\n","\n","## Unique Aspects of the Project\n","- **Ensemble Modeling**: The use of three different models and majority voting showcases the effectiveness of ensemble learning in achieving high prediction accuracy.\n","- **Data Imputation Strategy**: The employment of `IterativeImputer` for filling missing numeric values is a sophisticated approach that maintains data integrity and relationships between features.\n","- **Multi-Model Comparison**: This project emphasizes the importance of evaluating and comparing multiple models to ensure the best possible results, reflecting a thorough understanding of model performance and selection.\n","\n","## Conclusion\n","This project illustrates a complete machine learning pipeline, from data preprocessing to model training and final prediction submission, demonstrating effective techniques for personality classification based on behavioral characteristics. Future enhancements could include hyperparameter tuning, model optimization, and exploring additional algorithms or features to further improve classification accuracy."]},{"cell_type":"markdown","id":"f328f389","metadata":{"papermill":{"duration":0.003187,"end_time":"2025-07-02T18:33:52.553892","exception":false,"start_time":"2025-07-02T18:33:52.550705","status":"completed"},"tags":[]},"source":["# 2. Imports"]},{"cell_type":"code","execution_count":1,"id":"a34ed7a7","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-07-02T18:33:52.562164Z","iopub.status.busy":"2025-07-02T18:33:52.56184Z","iopub.status.idle":"2025-07-02T18:33:57.648209Z","shell.execute_reply":"2025-07-02T18:33:57.647057Z"},"papermill":{"duration":5.092854,"end_time":"2025-07-02T18:33:57.650224","exception":false,"start_time":"2025-07-02T18:33:52.55737","status":"completed"},"tags":[]},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd  # For data manipulation and analysis\n","import numpy as np  # For numerical operations\n","from sklearn.experimental import enable_iterative_imputer  # Needed to use IterativeImputer\n","from sklearn.impute import IterativeImputer  # For iterative imputation of missing values\n","from sklearn.model_selection import train_test_split  # For splitting the dataset into training and validation sets\n","from sklearn.ensemble import RandomForestClassifier  # Importing the Random Forest classifier for model training\n","from sklearn.metrics import classification_report, accuracy_score  # For evaluating model performance metrics\n","from catboost import CatBoostClassifier  # Importing the CatBoost classifier for gradient boosting on decision trees\n","import xgboost as xgb  # Importing the XGBoost classifier\n","from collections import Counter  # Importing Counter for counting hashable objects, useful for tallying predictions\n","from tabulate import tabulate  # For displaying the DataFrame with borders\n","from colorama import Fore, Style  # Import Colorama for coloring text"]},{"cell_type":"markdown","id":"59a0e1be","metadata":{"papermill":{"duration":0.003296,"end_time":"2025-07-02T18:33:57.657603","exception":false,"start_time":"2025-07-02T18:33:57.654307","status":"completed"},"tags":[]},"source":["# 3. Data Preprocessing for Personality Classification\n","\n","This notebook outlines the preprocessing steps taken to prepare data for a personality classification project on Kaggle, focusing on distinguishing between Introverts and Extroverts.\n","\n","## Preprocessing Function: `preprocess`\n","\n","1. **Copy DataFrame**: Creates a copy of the input DataFrame to avoid modifying the original.\n","\n","2. **Handle Categorical Variables**: Fills missing values in `Stage_fear` and `Drained_after_socializing` with 'Unknown' and maps them to numerical values:\n","   - `Yes` → 1\n","   - `No` → 0\n","   - `Unknown` → -1\n","\n","3. **Select Numeric Columns**: Specifies columns that will have missing values imputed:\n","   - `Time_spent_Alone`, `Social_event_attendance`, `Going_outside`, `Friends_circle_size`, `Post_frequency`\n","   \n","4. **Impute Missing Numeric Values**: Uses `IterativeImputer` to fill missing values in the selected numeric columns.\n","\n","5. **Return Preprocessed DataFrame**: Outputs the processed DataFrame.\n","\n","## Loading and Preprocessing the Data\n","\n","- Loads training and testing datasets.\n","- Preprocesses the training data by removing the `id` and `Personality` columns, then maps `Personality` to numerical values (0 for Introvert, 1 for Extrovert).\n","- Preprocesses the test data by removing the `id` column.\n","\n","## Conclusion\n","\n","This code effectively prepares the dataset by handling missing values and transforming categorical variables into numerical format, which is crucial for training machine learning models."]},{"cell_type":"code","execution_count":2,"id":"63882209","metadata":{"execution":{"iopub.execute_input":"2025-07-02T18:33:57.666101Z","iopub.status.busy":"2025-07-02T18:33:57.665614Z","iopub.status.idle":"2025-07-02T18:33:58.058549Z","shell.execute_reply":"2025-07-02T18:33:58.057222Z"},"papermill":{"duration":0.399058,"end_time":"2025-07-02T18:33:58.060229","exception":false,"start_time":"2025-07-02T18:33:57.661171","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["   Time_spent_Alone  Stage_fear  Social_event_attendance  Going_outside  \\\n","0               0.0           0                      6.0            4.0   \n","1               1.0           0                      7.0            3.0   \n","2               6.0           1                      1.0            0.0   \n","3               3.0           0                      7.0            3.0   \n","4               1.0           0                      4.0            4.0   \n","\n","   Drained_after_socializing  Friends_circle_size  Post_frequency  \n","0                          0                 15.0        5.000000  \n","1                          0                 10.0        8.000000  \n","2                         -1                  3.0        0.000000  \n","3                          0                 11.0        5.000000  \n","4                          0                 13.0        5.664129  \n","0    1\n","1    1\n","2    0\n","3    1\n","4    1\n","Name: Personality, dtype: int64\n","   Time_spent_Alone  Stage_fear  Social_event_attendance  Going_outside  \\\n","0          3.000000           0                      7.0            4.0   \n","1          7.408681           1                      0.0            0.0   \n","2          3.000000           0                      5.0            6.0   \n","3          3.000000           0                      4.0            4.0   \n","4          9.000000           1                      1.0            2.0   \n","\n","   Drained_after_socializing  Friends_circle_size  Post_frequency  \n","0                          0                  6.0         5.14554  \n","1                          1                  5.0         1.00000  \n","2                          0                 15.0         9.00000  \n","3                          0                  5.0         6.00000  \n","4                          1                  1.0         1.00000  \n"]}],"source":["def preprocess(df):\n","    # Make a copy of the DataFrame\n","    df = df.copy()\n","    \n","    # Fill categorical variables and map them to numeric values\n","    df['Stage_fear'] = df['Stage_fear'].fillna('Unknown').map({'Yes': 1, 'No': 0, 'Unknown': -1})\n","    df['Drained_after_socializing'] = df['Drained_after_socializing'].fillna('Unknown').map({'Yes': 1, 'No': 0, 'Unknown': -1})\n","    \n","    # Select numeric columns for imputation\n","    num_cols = ['Time_spent_Alone', 'Social_event_attendance', \n","                'Going_outside', 'Friends_circle_size', \n","                'Post_frequency']\n","    \n","    # Use IterativeImputer to fill missing numeric values\n","    imputer = IterativeImputer(random_state=42)\n","    df[num_cols] = imputer.fit_transform(df[num_cols])\n","    \n","    return df\n","\n","# Load the datasets\n","train = pd.read_csv('/kaggle/input/playground-series-s5e7/train.csv')\n","test = pd.read_csv('/kaggle/input/playground-series-s5e7/test.csv')\n","\n","# Preprocess training data\n","X = preprocess(train.drop(['id', 'Personality'], axis=1))\n","y = train['Personality'].map({'Introvert': 0, 'Extrovert': 1})  # Target variable\n","\n","# Preprocess test data\n","X_test = preprocess(test.drop('id', axis=1))\n","\n","# Optionally print the first few rows of preprocessed data to verify\n","print(X.head())\n","print(y.head())\n","print(X_test.head())"]},{"cell_type":"markdown","id":"22907139","metadata":{"papermill":{"duration":0.003337,"end_time":"2025-07-02T18:33:58.067295","exception":false,"start_time":"2025-07-02T18:33:58.063958","status":"completed"},"tags":[]},"source":["# 4. Model Training and Prediction for Personality Classification\n","\n","This section outlines the process of training a Random Forest classifier and making predictions for personality types.\n","\n","1. Split the preprocessed data into training and validation sets.\n","2. Initialize and train a Random Forest Classifier on the training data.\n","3. Evaluate the model's accuracy and performance on the validation set.\n","4. Predict personality types for the test dataset.\n","5. Map the predictions from numerical values back to 'Introvert' or 'Extrovert'.\n","6. Create a DataFrame with the test IDs and their corresponding predicted personalities.\n","7. Save the results to a CSV file for further analysis.\n","\n","This process allows for the classification of personalities based on behavioral traits using a machine learning approach."]},{"cell_type":"code","execution_count":3,"id":"96816392","metadata":{"execution":{"iopub.execute_input":"2025-07-02T18:33:58.076471Z","iopub.status.busy":"2025-07-02T18:33:58.075417Z","iopub.status.idle":"2025-07-02T18:33:59.565465Z","shell.execute_reply":"2025-07-02T18:33:59.564529Z"},"papermill":{"duration":1.496509,"end_time":"2025-07-02T18:33:59.567244","exception":false,"start_time":"2025-07-02T18:33:58.070735","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9670715249662618\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.92      0.94       952\n","           1       0.97      0.98      0.98      2753\n","\n","    accuracy                           0.97      3705\n","   macro avg       0.96      0.95      0.96      3705\n","weighted avg       0.97      0.97      0.97      3705\n","\n"]}],"source":["# Now proceed with the next steps\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train the model\n","model = RandomForestClassifier(random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Evaluate the model\n","y_pred = model.predict(X_val)\n","print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n","print(classification_report(y_val, y_pred))\n","\n","# Make predictions on the test data\n","test_predictions = model.predict(X_test)\n","\n","# Make predictions on the test data\n","test_predictions = model.predict(X_test)\n","\n","# Map back to original labels\n","test_predictions_labels = np.where(test_predictions == 0, 'Introvert', 'Extrovert')\n","\n","# Create a DataFrame to save the results with descriptive labels\n","results = pd.DataFrame({'id': test['id'], 'Predicted_Personality': test_predictions_labels})\n","\n","# Save to CSV\n","results.to_csv('result_r_forest.csv', index=False)\n"]},{"cell_type":"markdown","id":"6255e5b3","metadata":{"papermill":{"duration":0.003298,"end_time":"2025-07-02T18:33:59.574227","exception":false,"start_time":"2025-07-02T18:33:59.570929","status":"completed"},"tags":[]},"source":["# 5. CatBoost Model Training and Prediction for Personality Classification\n","\n","This section describes the steps for using the CatBoost classifier to predict personality types.\n","\n","1. Initialize the CatBoost model with specific parameters.\n","2. Fit the model on the training data.\n","3. Make predictions on the validation set and evaluate the model's accuracy and performance.\n","4. Predict personality types for the test dataset.\n","5. Map predictions back to 'Introvert' or 'Extrovert'.\n","6. Create a DataFrame to store the test IDs and predicted personalities.\n","7. Save the results to a CSV file for further analysis.\n","\n","This process employs the CatBoost algorithm for effective personality classification based on behavioral data."]},{"cell_type":"code","execution_count":4,"id":"be3aca83","metadata":{"execution":{"iopub.execute_input":"2025-07-02T18:33:59.582919Z","iopub.status.busy":"2025-07-02T18:33:59.582515Z","iopub.status.idle":"2025-07-02T18:34:02.55921Z","shell.execute_reply":"2025-07-02T18:34:02.558034Z"},"papermill":{"duration":2.983127,"end_time":"2025-07-02T18:34:02.560968","exception":false,"start_time":"2025-07-02T18:33:59.577841","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9673414304993252\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.93      0.94       952\n","           1       0.98      0.98      0.98      2753\n","\n","    accuracy                           0.97      3705\n","   macro avg       0.96      0.95      0.96      3705\n","weighted avg       0.97      0.97      0.97      3705\n","\n"]}],"source":["# Initialize the CatBoost model\n","catboost_model = CatBoostClassifier(iterations=500, learning_rate=0.1, depth=6, random_state=42, verbose=0)\n","\n","# Fit the model on the training data\n","catboost_model.fit(X_train, y_train)\n","\n","# Make predictions on the validation set\n","y_pred = catboost_model.predict(X_val)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n","print(classification_report(y_val, y_pred))\n","\n","# Make predictions on the test data\n","catboost_predictions = catboost_model.predict(X_test)\n","\n","# Map back to original labels\n","catboost_predictions_labels = np.where(catboost_predictions == 0, 'Introvert', 'Extrovert')\n","\n","# Create a DataFrame to save the results with descriptive labels\n","catboost_results = pd.DataFrame({'id': test['id'], 'Predicted_Personality': catboost_predictions_labels})\n","\n","# Save to CSV\n","catboost_results.to_csv('result_c_boost.csv', index=False)  # Save results"]},{"cell_type":"markdown","id":"e69a2f1d","metadata":{"papermill":{"duration":0.003275,"end_time":"2025-07-02T18:34:02.56778","exception":false,"start_time":"2025-07-02T18:34:02.564505","status":"completed"},"tags":[]},"source":["# 6. XGBoost Model Training and Prediction for Personality Classification\n","\n","This section outlines the use of the XGBoost classifier to predict personality types.\n","\n","1. Initialize the XGBoost model with specified parameters.\n","2. Fit the model on the training data.\n","3. Make predictions on the validation set and evaluate accuracy and performance.\n","4. Predict personality types for the test dataset.\n","5. Map predictions back to 'Introvert' or 'Extrovert'.\n","6. Create a DataFrame to store the test IDs and corresponding predicted personalities.\n","7. Save the results to a CSV file for further analysis.\n","\n","This process applies the XGBoost algorithm for effective personality classification based on behavioral data."]},{"cell_type":"code","execution_count":5,"id":"db090fa1","metadata":{"execution":{"iopub.execute_input":"2025-07-02T18:34:02.576055Z","iopub.status.busy":"2025-07-02T18:34:02.575739Z","iopub.status.idle":"2025-07-02T18:34:02.786844Z","shell.execute_reply":"2025-07-02T18:34:02.785886Z"},"papermill":{"duration":0.218054,"end_time":"2025-07-02T18:34:02.789259","exception":false,"start_time":"2025-07-02T18:34:02.571205","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9665317139001349\n","              precision    recall  f1-score   support\n","\n","           0       0.95      0.92      0.93       952\n","           1       0.97      0.98      0.98      2753\n","\n","    accuracy                           0.97      3705\n","   macro avg       0.96      0.95      0.96      3705\n","weighted avg       0.97      0.97      0.97      3705\n","\n"]}],"source":["# Initialize the XGBoost model\n","xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n","\n","# Fit the model on the training data\n","xgboost_model.fit(X_train, y_train)\n","\n","# Make predictions on the validation set\n","y_pred = xgboost_model.predict(X_val)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n","print(classification_report(y_val, y_pred))\n","\n","# Make predictions on the test data\n","xgboost_predictions = xgboost_model.predict(X_test)\n","\n","# Map back to original labels\n","xgboost_predictions_labels = np.where(xgboost_predictions == 0, 'Introvert', 'Extrovert')\n","\n","# Create a DataFrame to save the results with descriptive labels\n","xgboost_results = pd.DataFrame({'id': test['id'], 'Predicted_Personality': xgboost_predictions_labels})\n","\n","# Save to CSV\n","xgboost_results.to_csv('result_xg_boost.csv', index=False)  # Save results"]},{"cell_type":"markdown","id":"b0929120","metadata":{"papermill":{"duration":0.003309,"end_time":"2025-07-02T18:34:02.796257","exception":false,"start_time":"2025-07-02T18:34:02.792948","status":"completed"},"tags":[]},"source":["# 7. Merging Model Predictions and Final Voting\n","\n","This section of the notebook focuses on merging predictions from different models (Random Forest, CatBoost, and XGBoost) and applying majority voting to finalize the personality classification results.\n","\n","## Steps Overview\n","\n","1. **Load Results**: Import prediction results from the previously trained models.\n","2. **Load Test Data**: Import the original feature data associated with the test dataset.\n","3. **Ensure ID Consistency**: Convert all 'id' columns to string type to facilitate merging.\n","4. **Rename Prediction Columns**: Change prediction column names for clarity and consistency across models.\n","5. **Merge Predictions**: Combine the predictions from different models into a single DataFrame based on the 'id'.\n","6. **Define Majority Voting Function**: Establish a function to determine the final prediction based on the majority of model votes.\n","7. **Apply Majority Voting**: Use the voting function to derive the final predictions for each entry.\n","8. **Check for Divergence**: Create a new column indicating if the models disagreed on the predictions.\n","9. **Filter Divergent Predictions**: Retain only those rows where model predictions differ.\n","10. **Prepare Features DataFrame**: Create a DataFrame containing the relevant features for further analysis.\n","11. **Merge Feature Data with Divergent Predictions**: Combine the features with the predictions to analyze cases of divergence.\n","12. **Print Results**: Display the DataFrame containing divergent predictions along with their corresponding feature data.\n","\n","This approach allows for a comprehensive analysis of model predictions and helps ensure robust classification outcomes."]},{"cell_type":"code","execution_count":6,"id":"56bea028","metadata":{"execution":{"iopub.execute_input":"2025-07-02T18:34:02.805267Z","iopub.status.busy":"2025-07-02T18:34:02.804704Z","iopub.status.idle":"2025-07-02T18:34:02.946805Z","shell.execute_reply":"2025-07-02T18:34:02.945732Z"},"papermill":{"duration":0.148725,"end_time":"2025-07-02T18:34:02.94851","exception":false,"start_time":"2025-07-02T18:34:02.799785","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Divergent Predictions (with Feature Columns):\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","|    id | RF        | CB        | XGB       |   TSA | SF   |   SEA |   GO | DAS   |   FCS |   PF |\n","+=======+===========+===========+===========+=======+======+=======+======+=======+=======+======+\n","| 18753 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |   nan | No   |     9 |    6 | No    |     6 |    3 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 18876 | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m | Introvert |    10 | No   |   nan |    6 | No    |    10 |    7 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 18973 | Introvert | Introvert | \u001b[32mExtrovert\u001b[0m |     9 | Yes  |     2 |    0 | Yes   |   nan |    2 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 18977 | \u001b[32mExtrovert\u001b[0m | Introvert | \u001b[32mExtrovert\u001b[0m |     5 | No   |     9 |    7 | No    |    11 |    3 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 19707 | Introvert | \u001b[32mExtrovert\u001b[0m | Introvert |     2 | No   |     6 |    5 | No    |    15 |    9 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 19774 | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m | Introvert |     6 | No   |     9 |    3 | No    |    13 |    5 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 20017 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |     0 | Yes  |     3 |    3 | Yes   |     5 |    3 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 20033 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |   nan | Yes  |     2 |    2 | Yes   |     5 |    7 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 20153 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |     7 | Yes  |     2 |    7 | Yes   |     3 |    6 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 20905 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |     9 | nan  |     3 |    2 | Yes   |     4 |    0 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21051 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |     7 | Yes  |     0 |    1 | Yes   |     6 |    2 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21073 | Introvert | Introvert | \u001b[32mExtrovert\u001b[0m |    11 | Yes  |     1 |    3 | Yes   |     4 |    1 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21116 | Introvert | Introvert | \u001b[32mExtrovert\u001b[0m |    11 | Yes  |   nan |    1 | Yes   |     0 |    2 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21294 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |     0 | Yes  |     1 |    1 | Yes   |     3 |    1 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21333 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |    11 | Yes  |   nan |    2 | Yes   |     3 |    0 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21359 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |    11 | No   |     3 |    1 | No    |     4 |    2 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21881 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |    10 | Yes  |     0 |    2 | Yes   |   nan |    2 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 21932 | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m | Introvert |     8 | No   |     3 |    4 | No    |     5 |  nan |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 22291 | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m | Introvert |     4 | No   |     3 |  nan | No    |     2 |    2 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23026 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |     8 | Yes  |     2 |    0 | Yes   |   nan |    3 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23200 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |     2 | No   |     7 |    7 | No    |    11 |    9 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23291 | \u001b[32mExtrovert\u001b[0m | Introvert | \u001b[32mExtrovert\u001b[0m |   nan | No   |     7 |    7 | No    |    12 |    6 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23330 | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m | Introvert |     5 | No   |     9 |    7 | No    |    12 |    5 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23336 | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m | Introvert |     9 | No   |     2 |    4 | No    |     4 |    3 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23350 | \u001b[32mExtrovert\u001b[0m | Introvert | Introvert |     8 | No   |     9 |    6 | No    |    10 |    7 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23484 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |    11 | Yes  |     0 |    1 | Yes   |     0 |    2 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23491 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |    11 | Yes  |     1 |    3 | Yes   |     4 |    0 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 23822 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |     0 | No   |     9 |  nan | No    |    13 |    9 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 24005 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |     9 | No   |     9 |    7 | No    |    12 |   10 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 24135 | Introvert | \u001b[32mExtrovert\u001b[0m | Introvert |     7 | Yes  |     2 |    0 | Yes   |     1 |  nan |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n","| 24451 | Introvert | \u001b[32mExtrovert\u001b[0m | \u001b[32mExtrovert\u001b[0m |     3 | No   |     8 |    3 | No    |   nan |    6 |\n","+-------+-----------+-----------+-----------+-------+------+-------+------+-------+-------+------+\n"]}],"source":["# Load the results from previous models\n","rf_results = pd.read_csv('/kaggle/working/result_r_forest.csv')  # Random Forest results\n","catboost_results = pd.read_csv('/kaggle/working/result_c_boost.csv')  # CatBoost results\n","xgboost_results = pd.read_csv('/kaggle/working/result_xg_boost.csv')  # XGBoost results\n","# Load the original feature data (test set)\n","test_data = pd.read_csv('/kaggle/input/playground-series-s5e7/test.csv')  # Load test.csv\n","# Ensure all 'id' columns are of the same type (string)\n","rf_results['id'] = rf_results['id'].astype(str)\n","catboost_results['id'] = catboost_results['id'].astype(str)\n","xgboost_results['id'] = xgboost_results['id'].astype(str)\n","test_data['id'] = test_data['id'].astype(str)  # Ensure test data's 'id' is a string\n","# Rename the prediction columns for clarity\n","rf_results.rename(columns={'Predicted_Personality': 'RF'}, inplace=True)  # Rename for consistency\n","catboost_results.rename(columns={'Predicted_Personality': 'CB'}, inplace=True)  # Rename for consistency\n","xgboost_results.rename(columns={'Predicted_Personality': 'XGB'}, inplace=True)  # Rename for consistency\n","# Merge results on 'id'\n","comparison_df = rf_results.merge(catboost_results, on='id')\n","comparison_df = comparison_df.merge(xgboost_results, on='id')\n","# Define a function to determine majority voting\n","def majority_vote(row):\n","    predictions = [row['RF'], row['CB'], row['XGB']]\n","    return Counter(predictions).most_common(1)[0][0]  # Get the most common prediction\n","# Apply the majority vote function to each row\n","comparison_df['Final_Prediction'] = comparison_df.apply(majority_vote, axis=1)\n","# Create a new column to check if predictions differ\n","comparison_df['Divergence'] = (comparison_df['RF'] != comparison_df['Final_Prediction']) | \\\n","                              (comparison_df['CB'] != comparison_df['Final_Prediction']) | \\\n","                              (comparison_df['XGB'] != comparison_df['Final_Prediction'])\n","# Filter to keep only those rows where there is a divergence\n","divergent_predictions_df = comparison_df[comparison_df['Divergence']]\n","# Prepare features DataFrame\n","feature_columns = ['Time_spent_Alone', 'Stage_fear', \n","                   'Social_event_attendance', 'Going_outside', \n","                   'Drained_after_socializing', 'Friends_circle_size', \n","                   'Post_frequency']  # Original feature names\n","# Create a features DataFrame from the test data\n","features_df = test_data[feature_columns].copy()\n","features_df.columns = ['TSA', 'SF', 'SEA', 'GO', 'DAS', 'FCS', 'PF']  # Rename to abbreviations\n","# Ensure 'id' column in features_df for merging\n","features_df['id'] = test_data['id'].astype(str)  # Add the id for merging\n","# Merge the feature columns with the divergent predictions DataFrame\n","divergent_predictions_df = divergent_predictions_df.merge(features_df, on='id', how='left')\n","\n","# Prepare the DataFrame for printing\n","divergent_predictions_to_print = divergent_predictions_df[['id', 'RF', 'CB', 'XGB', 'TSA', 'SF', 'SEA', 'GO', 'DAS', 'FCS', 'PF']].copy()\n","\n","# Apply color formatting to 'Predicted_Personality' columns\n","def color_predictions(row):\n","    for column in ['RF', 'CB', 'XGB']:\n","        if row[column] == 'Extrovert':\n","            row[column] = f\"{Fore.GREEN}{row[column]}{Style.RESET_ALL}\"  # Color in green\n","    return row\n","\n","divergent_predictions_to_print = divergent_predictions_to_print.apply(color_predictions, axis=1)\n","\n","# Print the DataFrame with divergent predictions formatted with borders\n","print(\"\\nDivergent Predictions (with Feature Columns):\")\n","print(tabulate(divergent_predictions_to_print, headers='keys', tablefmt='grid', showindex=False))"]},{"cell_type":"markdown","id":"0f1c116d","metadata":{"papermill":{"duration":0.003618,"end_time":"2025-07-02T18:34:02.956068","exception":false,"start_time":"2025-07-02T18:34:02.95245","status":"completed"},"tags":[]},"source":["# 8. Generating Submission File from Model Predictions\n","\n","This section describes the process of creating the final submission file `submission.csv` using the predictions obtained from various machine learning models (Random Forest, CatBoost, and XGBoost).\n","\n","## Steps Overview\n","\n","1. **Load Predictions**: The predictions from the three models are loaded into a DataFrame named `comparison_df`. This DataFrame contains the predicted personality types from each model.\n","\n","2. **Define Voting Function**: A function (`final_prediction`) is defined to determine the final prediction for each entry by applying a majority voting mechanism. The function:\n","   - Counts the predictions from the three models for a given row.\n","   - Selects the prediction that appears most frequently as the final prediction.\n","\n","3. **Compute Final Predictions**: The majority vote function is applied to each row of the `comparison_df` to create a new column called `Final_Prediction`. This column encapsulates the final decision on the predicted personality based on the majority.\n","\n","4. **Prepare Submission DataFrame**: A new DataFrame (`submission_df`) is created containing only the `id` and the `Final_Prediction`, which is renamed to `Predicted_Personality` for clarity.\n","\n","5. **Save to CSV**: The final DataFrame is saved as a CSV file named `submission.csv`, ready for submission or further analysis.\n","\n","This approach ensures that the predictions included in the submission file are based on the majority consensus of the models, thereby increasing the chances of obtaining accurate and reliable results."]},{"cell_type":"code","execution_count":7,"id":"3df296d1","metadata":{"execution":{"iopub.execute_input":"2025-07-02T18:34:02.964796Z","iopub.status.busy":"2025-07-02T18:34:02.964422Z","iopub.status.idle":"2025-07-02T18:34:03.055481Z","shell.execute_reply":"2025-07-02T18:34:03.054344Z"},"papermill":{"duration":0.097263,"end_time":"2025-07-02T18:34:03.057059","exception":false,"start_time":"2025-07-02T18:34:02.959796","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Submission file 'submission.csv' has been created.\n"]}],"source":["import pandas as pd\n","from collections import Counter\n","\n","# Supondo que você tenha um DataFrame 'comparison_df' já preenchido com as previsões de RF, CB e XGB\n","\n","# Defina uma função para determinar a previsão final considerando a votação\n","def final_prediction(row):\n","    # Registra as previsões de cada modelo\n","    predictions = [row['RF'], row['CB'], row['XGB']]\n","    # Calcula a previsão da maioria\n","    majority_vote = Counter(predictions).most_common(1)[0][0]  # Obtém a previsão mais comum\n","    return majority_vote\n","\n","# Adicione a coluna de previsão final ao DataFrame\n","comparison_df['Final_Prediction'] = comparison_df.apply(final_prediction, axis=1)\n","\n","# Crie o DataFrame para submissão\n","submission_df = comparison_df[['id', 'Final_Prediction']].copy()\n","submission_df.rename(columns={'Final_Prediction': 'Predicted_Personality'}, inplace=True)\n","\n","# Salve o DataFrame como CSV\n","submission_df.to_csv('submission.csv', index=False)\n","\n","print(\"Submission file 'submission.csv' has been created.\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":12738969,"sourceId":91718,"sourceType":"competition"},{"datasetId":7787766,"sourceId":12352749,"sourceType":"datasetVersion"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":17.664239,"end_time":"2025-07-02T18:34:03.882445","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-02T18:33:46.218206","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}